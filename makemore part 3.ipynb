{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df29115-a89e-48d5-97f7-3065f9bbfd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a6ce3f-2178-4114-acc0-cc20b25554e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lecture de tous les mots\n",
    "words = open('dataset/names.txt', 'r').read().splitlines()\n",
    "words [:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80a36898-1c35-4e83-a45d-3a9df2878544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "#Cr√©ation des dictionnaires\n",
    "chars = sorted(list(set(''.join(words)))) # estraction de chaque carac√®re de la liste de mots\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)} # Cr√©ation d'un liste en commen√ßant √† l'indice 1 ou chaque caract√®re est associc√© √† un index\n",
    "stoi['.'] = 0 #jout du caract√®re \".\" √† l'indice 0\n",
    "itos = {i:s for s,i in stoi.items()} # Cr√©ation d'une liste inverse pour avoir le nombre et la corespondance du caractere\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c390758-3d4d-40f4-a874-530d13b928f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construction du dataset\n",
    "block_size = 3 # taille du contexte dans cet exemple \n",
    "\n",
    "X, Y = [], [] #Cr√©ation de deux liste X pour les entr√©es et Y pour la sortie attendue\n",
    "\n",
    "for w in words:\n",
    "    #print (w)\n",
    "    context = [0] * block_size # On initie le contexte avec [0, 0, 0]\n",
    "    for ch in w + '.': # Pour chauqe catact√®re du mot\n",
    "\n",
    "        ix = stoi[ch] # On r√©cup√®re la valeur du nombre correspondant √† la lettre\n",
    "        X.append(context) # On ajoute le contexte √† la liste X\n",
    "        Y.append(ix) # On ajoute la valeur num√©rique du caract√®re √† la liste Y\n",
    "        \n",
    "        #On affiche le contexte + ----> + le caract√®re du mot que l'on traite \n",
    "            #print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        # La m√™me chose mais on affiche les indexes\n",
    "            #print(''.join(str(i) for i in context), '--->', ix)\n",
    " \n",
    "        \n",
    "        \n",
    "        # On jette le premier √©l√©ment du contexte et on d&calle tout a gauche\n",
    "        #et on ajoute la valeur num√©rique de la lettre dans le contexte\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "\n",
    "n_lignes_exemples = X.shape[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec19080-9bac-4cc5-b7fe-cb6a28393e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.int64, torch.Size([228146]), torch.int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a73b41e-d517-43af-878f-dd0c7e0ff9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cr√©ation de la matrice des embeddings, ou chaque caract√®re est \n",
    "# repr√©sent√© par une matrice a deux dimensions al√©aroires pour commencer\n",
    "C = torch.randn((27, 2))\n",
    "#print (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a16eae17-a2a4-4719-b13a-a5cdacf0301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "####### CONSTRUCTION DE LA COUCHE D'EMBEDDING ########\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2ba1ae9-523d-4ff3-b9d9-a739a36c1ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228146, 3, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding de la matric X\n",
    "# A ce stade X contient les contexte de 3 index\n",
    "# Le r√©seau ne peut pas travailler avec ces indexes c'est pourquoi on va \n",
    "# embedder X pour donner un repr√©sentation math√©matique des caract√®res via\n",
    "# des vecteurs denses\n",
    "# Avant embedding = X[i] = [5, 13, 13]\n",
    "# Apr√®s embedding = X[i] = [[1.7, -0.3], [0.2, +1.5], [0.2, +1.5]]\n",
    "# [\n",
    "      #C[5],    # embedding de 'e' ‚Üí [1.7, -0.3]\n",
    "      #C[13],   # embedding de 'm' ‚Üí [0.2, +1.5]\n",
    "      #C[13]    # embedding de 'm' ‚Üí [0.2, +1.5]\n",
    "# ]\n",
    "emb = C[X]\n",
    "# On obtient un tenseur de 32 lignes (le nombre d'exemple dans notre training set), dans chaque ligne 3 √©l√©ments (contexte) \n",
    "# et pour chaque √©l√©ment la version embedder donc une matrice de 2 dimensions\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb97c7e3-9f10-41e2-94a3-8c6fc98eff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "######### CONSTRUCTION DE LA HIDDEN LAYER ############\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a78f30e-d7e3-43a0-900e-3160e368ad1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape emb : torch.Size([228146, 3, 2])\n",
      "shape W1 : torch.Size([6, 100])\n",
      "shape b1 : torch.Size([100])\n",
      "shape emb.view(-1, 6) : torch.Size([228146, 6])\n",
      "shape de h : torch.Size([228146, 100])\n"
     ]
    }
   ],
   "source": [
    "#Initialisatin des poids al√©atoirement\n",
    "W1 = torch.randn((6, 100)) \n",
    "# 6 lignes car \n",
    "# 6 entr√©es car notre embedding contient 6 valeurs par ligne\n",
    "# 3 lettres de contexte * 2 embedding par lettre  \n",
    "# [[1.7, -0.3], [0.2, +1.5], [0.2, +1.5]]\n",
    "# La matrice est applatit avant d'√™tre envoy√© au neuronne pour ne faire q'un seul vecteur\n",
    "# [1.7, -0.3, 0.2, 1.5, 0.2, 1.5]   # vecteur de taille 6\n",
    "\n",
    "# 100 neuronnes cach√©s avec 6 poids => Taille initi√© √† l'exp√©rience :) \n",
    "\n",
    "#Initialisation des biais al√©atoirement\n",
    "b1 = torch.randn(100)\n",
    "# 100 biais car 100 neuronnes\n",
    "#Chaque neuronne re√ßoit la valeur de l'embedding applati,\n",
    "\n",
    "\n",
    "# Il fait son calcul tanh(aX + b) et en sortie on a une valeur\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "\n",
    "#Explication du emb.view\n",
    "# A ce stade on veut muliplier une matrice emb de dimensions [32, 3, 2]\n",
    "# par la matrice W1 de dimension [6, 100]\n",
    "# Ce qui est imossible, la multiplication d'une matrice A par une matrice B impose\n",
    "# que le nombre de colonne de la matrice A soit √©gal au nombre de ligne de la matrice B\n",
    "# Il faut donc que la matrice emb ai 6 colonne (actuellement 3)\n",
    "# la fonction view permet, sans cr√©er de nouveau tenseur en m√©moire, de transoformer \n",
    "# la forme de notre matrice et pour garder une forme dynamique on indique -1 au niveau\n",
    "# de la ligne, torch sait alors que ce sera forc√©ment 32 dans notre cas car il fait\n",
    "# autmatiquement le calcul en fonction de la taille du tenseur d'origine\n",
    "# origine 32 * 3 * 2 = 192 donc si on indique 6 il fait 192 / 6 pour d√©duire 32\n",
    "\n",
    "print('shape emb :', emb.shape)\n",
    "print('shape W1 :', W1.shape)\n",
    "print('shape b1 :', b1.shape)\n",
    "print('shape emb.view(-1, 6) :', emb.view(-1, 6).shape)\n",
    "\n",
    "# La shape de h sera √©gale au nombre de ligne de la matrice emb.view(-1, 6) >> 32\n",
    "# Et du nombre de colonne de la matrice W1 >> 100\n",
    "# R√®gle de la multiplication des matrices\n",
    "\n",
    "##  R√®gle math√©matique d'addition de matrice, pour addition deux matrices il faut qu'elle soient de m√™m taille :\n",
    "# L'addition de emb.view(-1, 6) @ W1  b1 √† 1 dimension  est possible grace au\n",
    "# Broadcasting, qui va √©tendre automatiquement le plus petit vecteur pour que la forme soit compatible\n",
    "# b1 est un vecteru compos√© d'une ligne et de 100 valeurs (colonnes)\n",
    "# Pour permettre l'addition le broadcasting va r√©p√©t√© virtuellement b1 sur 32 lignes\n",
    "print('shape de h :', h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a8613d0-02a1-4f23-9ba2-0caa815583a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "######## CONSTRUCTION DE LA COUCHE DE SORTIE #########\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f21366d7-6e33-4238-ba11-b4b003eb6bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisatin des poids al√©atoirement\n",
    "W2 = torch.randn((100, 27)) \n",
    "# 100 lignes car \n",
    "# 100 sorties de notre hidden layer (shape de h : torch.Size([32, 100]))\n",
    "# 27 colonnes car 27 sortie √©tant donn√©es le nombre de caract√®re possible   \n",
    "\n",
    "#Initialisation des biais al√©atoirement\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14db8231-d0b2-4a22-bf49-0d21e96dfed9",
   "metadata": {},
   "source": [
    "#### 1. 27 Scores bruts non normalis√©s, un niveau \"d'energie attribu√© a chaque caract√®re\"\n",
    "logits = h @ W2 + b2\n",
    "\n",
    "#### On va calculer la probabilit√©\n",
    "    # counts = logits.exp() # Transforme chaque score brut en nombre strictement positif \n",
    "    # on le divise par la valeur des sommes de toutes les colonnes pour en faire une moyenne ¬ª\n",
    "    # prob = counts / counts.sum(1, keepdims=True) ## Normalisation pour que la somme d'une ligne soit √©gale √† 1\n",
    "##### prob contient 32 lignes (nombre d'exemple) et 27 colonne repr√©sentant chauqe caract√®re et la probabilit√© affect√© a chaque caract√®re\n",
    "##### Cr√©ation d'un vecteur de 32 valeurs dans le quel on stock la valeur pr√©dite par le mod√®le\n",
    "##### Pour chaque caract√®re qui √©tait attendu (donc ce n'est forc√©ment celui qui a eu la meilleur probabilit√©\n",
    "##### Ce qui est normal, √† ce stade le mod√®le n'est pas encore entrain√©)\n",
    "    # preparationCalculLoss = prob[torch.arange(32), Y]\n",
    "    # print (preparationCalculLoss)\n",
    "\n",
    "##### On prend la probabilit√© du caract√®re correct, on prend son log, on met un signe moins, on moyenne :\n",
    "##### c‚Äôest la Negative Log-Likelihood, la mesure standard de ‚Äú√† quel point le mod√®le a eu tort‚Äù.\n",
    "##### C'est cette valeur que l'on va tenter de minimiser pour am√©liorer notre mod√®le\n",
    "    # loss = -preparationCalculLoss.log().mean()\n",
    "    # print (loss.item())\n",
    "\n",
    "#### La fonction F.cross_entropy(logits, y) faile calcul du neagative loglikelihood de fa√ßon plus efficiente\n",
    "#### cross_entropy fait tout en une seule op√©ration efficace au lieu de 4 quand on le fait manuellement\n",
    "#### cross_entropy est NUM√âRIQUEMENT STABLE >> \n",
    "    # Si un logit = 50 ‚Üí exp(50) ‚âà 5 √ó 10¬≤¬π ‚Üí explosion\n",
    "    # Si un logit = ‚Äì50 ‚Üí exp(‚Äì50) ‚âà 1.9e‚Äì22 ‚Üí underflow\n",
    "        # ‚û°Ô∏è aucun overflow\n",
    "        # ‚û°Ô∏è aucun underflow\n",
    "        # ‚û°Ô∏è m√™me si les logits sont √©normes\n",
    "        # ‚û°Ô∏è gradients fiables\n",
    "#### C‚Äôest plus rapide (impl√©ment√© en C++/CUDA)\n",
    "     # loss = F.cross_entropy(logits, Y)\n",
    "     # print('Caclul de la loss: ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88020f6-1fc4-4901-8c09-747c0888ae3d",
   "metadata": {},
   "source": [
    "######################################################\n",
    "################### Entrainement #####################\n",
    "######################################################\n",
    "parameters = [C, W1, W2, b1, b2]\n",
    "# Si on ne fait pas √ßa on a cette erreur\n",
    "# RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "# Afficher le nombre de param√®tre\n",
    "print('Notre mod√®le compte ',sum(p.nelement() for p in parameters), ' param√®tres')\n",
    "\n",
    "for k in range(10000): # Sur deux cents it√©rations\n",
    "\n",
    "    #Construction d'un minibach\n",
    "    # Le but ici est d'acc√©lerer l'entrainement et de consommer moins de RAM et de CPU\n",
    "    # Sans le batch, on fait entraine le r√©seau sur tout le dataset d'un coup\n",
    "    # Donc on fait plus de 220k forward et backward avec toutes les donn√©es en m√™me temps\n",
    "    ix = torch.randint(0, X.shape[0], (32,)) #Cette ligne tire 32 indices al√©atoires dans le dataset pour construire un mini-batch.\n",
    "\n",
    "    # Remarque : \n",
    "            # ce batching implique parfois la r√©utilisatin du m√™me exemple\n",
    "            # Certains exemples ne seront pas utilis√©s (environ 40% sur des batch de 32 exemples dans 200 it√©rations)\n",
    "            # Malgr√©s cela la descente de gradiant reste bonne\n",
    "            # C'est la technique utilis√© par les LLMs comme Llama ou Gemini\n",
    "    \n",
    "    # 1) Forward pass\n",
    "    emb = C[X[ix]]    \n",
    "    #Cette ligne remplace les indices des caract√®res du mini-batch par leur embedding dense, \n",
    "    #cr√©ant un tenseur [32,3,2] pr√™t pour la couche cach√©e.\n",
    "    \n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)   # Hidden layer [32, 100]\n",
    "    logits = h @ W2 + b2           # Couche de sortie [32, 27] \n",
    "    loss = F.cross_entropy(logits, Y[ix]) # Calcul de la loss (exp + counts / counts.sum ...) \n",
    "\n",
    "    # 2) Backprop\n",
    "    # Les gradients sont g√©n√©r√©s et stock√©s automatiquement par loss.backward() \n",
    "    # et on les efface manuellement juste apr√®s les avoir utilis√©s pour mettre √† jour les poids\n",
    "    for p in parameters:\n",
    "        p.grad = None  \n",
    "    \n",
    "    loss.backward() \n",
    "\n",
    "    # 3) Gradient descent >> Mise √† jour des poids\n",
    "    for p in parameters:\n",
    "        p.data += -0.001 * p.grad    # descente de gradiant\n",
    "\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9e4bf0-bef6-495c-9b37-ef1dd9737020",
   "metadata": {},
   "source": [
    "<h2 style=\"color: red;\">üî• Note sur la d√©finition du learning rate</h2>\n",
    "\n",
    "Pour trouver une bonne valeur du learning rate, La m√©thode utilis√©e en deep learning moderne :\n",
    "\n",
    "On teste plusieurs learning rates :\n",
    "par ex. [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "\n",
    "On lance quelques it√©rations pour chaque valeur\n",
    "\n",
    "On observe la courbe de loss\n",
    "\n",
    "‚úî Le bon learning rate est : \n",
    "celui o√π la loss baisse rapidement sans instabilit√© et sans oscillations violentes\n",
    "\n",
    "### üî• Qu‚Äôest-ce que torch.linspace ?\n",
    "\n",
    "#torch.linspace(start, end, steps) cr√©e un vecteur de valeurs r√©guli√®rement espac√©es entre start et end.\n",
    "torch.linspace(0, 1, 5)\n",
    "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000]) >> 5 valeurs √©galement esp√©c√©es entre 0 et 1\n",
    "\n",
    "Dans notre exp√©rimentation, on va tester plusieurs valeurs possibles du learning rate.\n",
    " Le principe :\n",
    " - On boucle sur ~100 it√©rations d'entra√Ænement pour chaque learning rate test√©\n",
    " - √Ä chaque essai, on enregistre : \n",
    "       ‚Ä¢ la valeur du learning rate utilis√©\n",
    "       ‚Ä¢ la loss obtenue apr√®s ces it√©rations\n",
    " - Ensuite, on trace une courbe (loss en fonction du learning rate)\n",
    "   afin d‚Äôidentifier la valeur qui permet au mod√®le d‚Äôapprendre le plus efficacement.\n",
    "\n",
    " Cette m√©thode est une pratique courante en deep learning : elle permet de choisir\n",
    " un learning rate qui fait descendre la loss rapidement, sans instabilit√©s.\n",
    "\n",
    "Une fois le learning rate optimal identifi√©, on entra√Æne le mod√®le avec cette valeur jusqu‚Äô√† atteindre un palier (plateau de loss).\n",
    "Pour affiner encore la convergence, on r√©duit ensuite le learning rate d‚Äôun facteur 10 et on continue l‚Äôentra√Ænement : cela permet souvent de diminuer la loss un peu plus finement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adcc719-b2d5-4594-aada-c9ce11c697da",
   "metadata": {},
   "source": [
    "<h2 style=\"color: red;\">üî• Le standart dans les entrainements de mod√®le est de d√©couper le dataset en 3 parties\n",
    "</h2>\n",
    "\n",
    "#### ---> La partie entrainement (80% des donn√©es)\n",
    " ####     -  pour entrainer les param√®tres du mod√®le C, W1, W2, b1, b2\n",
    "#### ---> La partie dev / validation (10% des donn√©es)\n",
    " ####     -pour tester les hyperparam√®tres learning rate, taille du batch, dimensions de embeddings, taille du hiden                layer, architecture\n",
    "#### ---> La partie test (10% des donn√©es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "27f2b1b5-7732-418d-9021-9f93d18aa8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25626\n",
      "28829\n",
      "dataset d'entrainement :  182762  trigrammes\n",
      "dataset de dev / Validation :  22644  trigrammes\n",
      "dataset de test :  22740  trigrammes\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "## Cr√©ation des datasets d'entainement/ dev / test ###\n",
    "######################################################\n",
    "\n",
    "# Cr√©ation d'une fonction r√©utilisatble\n",
    "def build_dataset(words):\n",
    "    block_size = 3 # taille du contexte dans cet exemple \n",
    "    \n",
    "    X, Y = [], [] #Cr√©ation de deux liste X pour les entr√©es et Y pour la sortie attendue\n",
    "    \n",
    "    for w in words:\n",
    "        context = [0] * block_size # On initie le contexte avec [0, 0, 0]\n",
    "        for ch in w + '.': # Pour chauqe catact√®re du mot\n",
    "    \n",
    "            ix = stoi[ch] # On r√©cup√®re la valeur du nombre correspondant √† la lettre\n",
    "            X.append(context) # On ajoute le contexte √† la liste X\n",
    "            Y.append(ix) # On ajoute la valeur num√©rique du caract√®re √† la liste Y\n",
    "            \n",
    "            # On jette le premier √©l√©ment du contexte et on d&calle tout a gauche\n",
    "            #et on ajoute la valeur num√©rique de la lettre dans le contexte\n",
    "            context = context[1:] + [ix]\n",
    "    \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    #print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "# Utilisation de la fonction pour cr√©er les diff√©rents dataset\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words) # On m√©lange al√©atoirment la liste de mot\n",
    "n1 = int(0.8*len(words))\n",
    "print(n1)\n",
    "n2 = int(0.9*len(words))\n",
    "print(n2)\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1]) # On cr√©er une liste avec les mots compris dans le mot 1 et le mot 25626 (80%)\n",
    "Xdev, Ydev = build_dataset(words[n1:n2]) # On cr√©er une liste avec les mots compris  entre le mot 25626 et le mot 28829 (10%)\n",
    "Xte, Yte = build_dataset(words[n2:]) # On cr√©er une liste avc les mots apr√®s 28829 (10%)\n",
    "\n",
    "print('dataset d\\'entrainement : ', Xtr.shape[0], ' trigrammes')\n",
    "print('dataset de dev / Validation : ', Xdev.shape[0], ' trigrammes')\n",
    "print('dataset de test : ', Xte.shape[0], ' trigrammes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d924cb54-d011-4be0-828c-4f3dcdcf7aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notre mod√®le compte  18167  param√®tres\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "################### PARAM√àTRES #######################\n",
    "######################################################\n",
    "pw1 = 200 ## Nb de poids dans la hidden couche\n",
    "pemb = 20 ## Nb de dimensions dans l'embeddding\n",
    "nbcar = 27 ## Nb de caract√®res\n",
    "pembXtrig = pemb * block_size # la taille du contexte * la taille de l'embedding\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((nbcar, pemb)) # Couche d'embedding\n",
    "W1 = torch.randn((pembXtrig, pw1)) # Poids Hidden Layer\n",
    "b1 = torch.randn(pw1) # Biais Hidden layer\n",
    "W2 = torch.randn((pw1, nbcar)) # Poids sortie\n",
    "b2 = torch.randn(nbcar) # Biais sortie\n",
    "parameters = [C, W1, W2, b1, b2]\n",
    "\n",
    "# Afficher le nombre de param√®tre\n",
    "print('Notre mod√®le compte ',sum(p.nelement() for p in parameters), ' param√®tres')\n",
    "\n",
    "# Si on ne fait pas √ßa on a cette erreur\n",
    "# RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n",
    "lre = torch.linspace (-3, 0, 60000) ##g√©n√®re 60000 valeurs iniform√©ment r√©parties entre -3 et 0\n",
    "#print (lre) # tensor([-3.0000, -2.9970, -2.9940, -2.9910, -2.9880, -2.9850, ...]\n",
    "lrs = 10**lre # Exponentiel en base 10 √† chaque √©l√©ment > Transforme les exposants lre en learning rates\n",
    "# Permte de tester sur diff√©rents ordre de grandeur (0,1 / 0,01 / 0,001 ...)  pliutot que sue un espacement lin√©aire (-3.0000, -2.9970, -2.9940)\n",
    "#print (lrs) # ([0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "aac2cfef-aca8-4347-877e-a7abe7aeb60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lri, lossi, stepi = [], [], [] ## Stockage des learning rates essay√© avec les les loss asosci√©s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "12b8d985-0eb3-481d-b654-3947a101c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "################### ENTRAINEMENT #####################\n",
    "######################################################\n",
    "batchSize = 128\n",
    "\n",
    "for i in range(80000): \n",
    "\n",
    "    #Construction d'un minibach\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batchSize,)) #Cette ligne tire 32 indices al√©atoires dans le dataset pour construire un mini-batch.\n",
    "    \n",
    "    # 1) Forward pass\n",
    "\n",
    "    # 1.1) Embedding\n",
    "    emb = C[Xtr[ix]]    \n",
    "    #Cette ligne remplace les indices des caract√®res du mini-batch par leur embedding dense, \n",
    "    #cr√©ant un tenseur [32,3,2] pr√™t pour la couche cach√©e.\n",
    "\n",
    "    # 1.2) Hidden layer\n",
    "    h = torch.tanh(emb.view(-1, pembXtrig) @ W1 + b1)   # Hidden layer [32, 100]\n",
    "\n",
    "    # 1.3) Sortie \n",
    "    logits = h @ W2 + b2           # Couche de sortie [32, 27] \n",
    "    \n",
    "    loss = F.cross_entropy(logits, Ytr[ix]) # Calcul de la loss (exp + counts / counts.sum ...) \n",
    "\n",
    "    # 2) Backprop\n",
    "    for p in parameters:\n",
    "        p.grad = None  \n",
    "    loss.backward() \n",
    "\n",
    "    # 3) Mise √† jour des lri et lossi\n",
    "    #lr = lrs[i]\n",
    "    lr = 0.015\n",
    "\n",
    "    # 3) Gradient descent >> Mise √† jour des poids\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad    # descente de gradiant\n",
    "\n",
    "    # Track stats\n",
    "    #lri.append(lre[i])\n",
    "    stepi.append(i)\n",
    "    lossi.append(loss.item())\n",
    "\n",
    "## Affich√© la courbe avec matplot des learning rates et loss pour voir ou se situe le learnig rate le plus efficace et stable\n",
    "#plt.figure(figsize=(10,5))\n",
    "#plt.plot(lrs[:len(lossi)], lossi)\n",
    "#plt.xscale('log')\n",
    "#plt.xlabel('Learning rate (log scale)')\n",
    "#plt.ylabel('Loss')\n",
    "#plt.title('LR Finder ‚Äì Evolution de la loss en fonction du learning rate')\n",
    "#plt.grid(True)\n",
    "#plt.show()\n",
    "\n",
    "#print('Loss Entrainement: ',loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "bb9f4cd8-192a-4f58-80ae-4ffb0eb5dbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x172776a10>]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(stepi, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "441729aa-01c5-4f05-8af0-ca040994fcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Fin entrainement :  2.039626121520996\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "###### EVALUATION AVEC DONN√âES D'ENTRAINEMENT ########\n",
    "######################################################\n",
    "# Embedding\n",
    "emb = C[Xtr]\n",
    "# 1.2) Hidden layer [32, 100]\n",
    "h = torch.tanh(emb.view(-1, pembXtrig) @ W1 + b1)  \n",
    "# 1.3) Sortie [32, 27]\n",
    "logits = h @ W2 + b2      \n",
    "lossEval = F.cross_entropy(logits, Ytr)\n",
    "print('Loss Fin entrainement : ',lossEval.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2ce934d6-3c2a-486e-80a6-c1da55a93496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Dev:  2.149564743041992\n"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "###### EVALUATION AVEC DONN√âES DE VALIDATION #########\n",
    "######################################################\n",
    "# Embedding\n",
    "emb = C[Xdev]\n",
    "# 1.2) Hidden layer [32, 100]\n",
    "h = torch.tanh(emb.view(-1, pembXtrig) @ W1 + b1)  \n",
    "# 1.3) Sortie [32, 27]\n",
    "logits = h @ W2 + b2      \n",
    "lossEval = F.cross_entropy(logits, Ydev)\n",
    "print('Loss Dev: ',lossEval.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833dc09d-4e2c-44c3-afd6-0fb7fd4c4dc9",
   "metadata": {},
   "source": [
    "<h2 style=\"color: red;\">üî• Note sur l'entrainement</h2>\n",
    "\n",
    "### Il faut tester diff√©rentes variations de hyperparam√®tres \n",
    "#### * Variation de la taille des embeddiings des caract√®res\n",
    "#### * Variation de la taille du hiden layer (nombre de neuronne)\n",
    "#### * Refaire le calcul du learning rate le plus adapt√© lors des chnagements\n",
    "\n",
    "### L'objectif √©tant d'avoir la losss la plus basse possible\n",
    "\n",
    "<table border=\"1\" cellpadding=\"8\" style=\"border-collapse: collapse; text-align: center;\">\n",
    "  <thead style=\"background-color:#blue;\">\n",
    "    <tr>\n",
    "      <th>Mesure</th>\n",
    "      <th>Embedding 2 dims<br>Hidden 100 neurones</th>\n",
    "      <th>Embedding 10 dims<br>Hidden 300 neurones</th>\n",
    "      <th>Embedding 20 dims<br>Hidden 100 neurones</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td><b>Total param√®tres</b></td>\n",
    "      <td> 3481 </td>\n",
    "      <td> 17697 </td>\n",
    "      <td> 18167 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>Learning rate utilis√©</b></td>\n",
    "      <td> 0.1 </td>\n",
    "      <td> 0.15 </td>\n",
    "      <td> 0.15 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>Taille du batch utilis√©</b></td>\n",
    "      <td> 32 </td>\n",
    "      <td> 32 </td>\n",
    "      <td> 128 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>Traitement compl√©mentaire avec affinage du learning rate</b></td>\n",
    "      <td> 0.01 </td>\n",
    "      <td> 0.015 </td>\n",
    "      <td> 0.015 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><b>Loss obtenue</b></td>\n",
    "      <td> 2.6</td>\n",
    "      <td> 2.06</td>\n",
    "      <td> 2.03</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70c23cf-5ed2-45d8-a346-0da1c85d6d21",
   "metadata": {},
   "source": [
    "# Fin de makemore partie 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
